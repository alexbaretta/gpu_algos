// Copyright (c) 2025 Alessandro Baretta
// All rights reserved.

// source path: include/hip/benchmark/benchmark_tensor3d_2in_1out.hiph

#pragma once

#include <iostream>
#include <chrono>
#include <iomanip>
#include <Eigen/Dense>

#include <hip/hip_runtime.h>
#include <cxxopts.hpp>

#include "common/types/tensor3d.hpp"
#include "hip/check_errors.hiph"
#include "hip/hip_utils.hiph"
#include "hip/kernel_api/tensor3d_2in_1out.hiph"

template <TENSOR3D_KERNEL_2IN_1OUT Tensor3D_Kernel_2In_1Out>
class Benchmark_Tensor3D_2In_1Out {
    public:
    using Kernel_spec = typename Tensor3D_Kernel_2In_1Out::Kernel_spec;
    using Number = typename Tensor3D_Kernel_2In_1Out::Number;
    using Printable_Number = std::conditional_t<std::is_same_v<Number, __half>, float, Number>;

    const Kernel_spec spec;
    const int seed;
    const int gpu_mem;
    const bool verbose;
    const bool errors;
    const bool force;
    const std::string init_method;

    Tensor3D_Kernel_2In_1Out kernel;

    template <typename... Args>
    Benchmark_Tensor3D_2In_1Out(
        const Kernel_spec spec,
        const cxxopts::Options& options,
        const cxxopts::ParseResult& options_parsed,
        Args&... args
    ) : spec(spec),
        seed(options_parsed["seed"].as<long>()),
        gpu_mem(options_parsed["gpumem"].as<long>()),
        verbose(options_parsed["verbose"].as<bool>()),
        errors(options_parsed["errors"].as<bool>()),
        force(options_parsed["force"].as<bool>()),
        init_method(options_parsed["init-method"].as<std::string>()),
        kernel(spec, args...)
    {
        // Handle help option first
        if (options_parsed.count("help")) {
            std::cout << options.help() << std::endl;
            exit(0);
        }
        if (verbose && (
            (spec.n_rows_A_ > 10000 || spec.n_cols_A_ * spec.n_sheets_A_ > 1000)
            || (spec.n_rows_B_ > 10000 || spec.n_cols_B_ * spec.n_sheets_B_ > 1000)
            || (spec.n_rows_C_ > 10000 || spec.n_cols_C_ * spec.n_sheets_C_ > 1000)
        )) {
            std::cerr << "WARNING: verbose mode is enabled and the input tensors are large."
            << "This will print the entire tensors to the console." << std::endl;
            if (!force) {
                std::cerr << "Use --force to override." << std::endl
                          << "[ERROR] tensors too big for verbose mode" << std::endl;
                exit(1);
            }
        }
    }

    int run() {
        const size_t size_A = size_t(spec.n_rows_A_) * size_t(spec.n_cols_A_) * size_t(spec.n_sheets_A_);
        const size_t size_B = size_t(spec.n_rows_B_) * size_t(spec.n_cols_B_) * size_t(spec.n_sheets_B_);
        const size_t size_C = size_t(spec.n_rows_C_) * size_t(spec.n_cols_C_) * size_t(spec.n_sheets_C_);
        const size_t size_temp = size_t(spec.n_rows_temp_) * size_t(spec.n_cols_temp_) * size_t(spec.n_sheets_temp_);
        const size_t size_A_bytes = size_A * sizeof(Number);
        const size_t size_B_bytes = size_B * sizeof(Number);
        const size_t size_C_bytes = size_C * sizeof(Number);
        const size_t size_temp_bytes = size_temp * sizeof(Number);
        const size_t input_size_bytes = size_A_bytes + size_B_bytes;
        const size_t output_size_bytes = size_C_bytes;
        const size_t temp_size_bytes = size_temp_bytes;
        const size_t mem_size_bytes = input_size_bytes + output_size_bytes + temp_size_bytes;
        constexpr float GB = 1024.0f * 1024.0f * 1024.0f;
        const float input_size_gb = input_size_bytes / GB;
        const float output_size_gb = output_size_bytes / GB;
        const float temp_size_gb = temp_size_bytes / GB;
        const float mem_gb = mem_size_bytes / GB;

        const auto [is_random, is_increasing, is_decreasing] = [&](){
            if (init_method == "random") {
                return std::tuple{true, false, false};
            } else if (init_method == "increasing") {
                return std::tuple{false, true, false};
            } else if (init_method == "decreasing") {
                return std::tuple{false, false, true};
            } else {
                std::cerr << "[ERROR] Invalid initialization method" << std::endl;
                exit(1);
            }
        }();

        std::cout
            << "Input tensor3d A dimensions : " << spec.n_rows_A_ << "x" << spec.n_cols_A_ << "x" << spec.n_sheets_A_ << "\n"
            << "Input tensor3d B dimensions : " << spec.n_rows_B_ << "x" << spec.n_cols_B_ << "x" << spec.n_sheets_B_ << "\n"
            << "Output tensor3d dimensions  : " << spec.n_rows_C_ << "x" << spec.n_cols_C_ << "x" << spec.n_sheets_C_ << "\n"
            << "Temp tensor3d dimensions    : " << spec.n_rows_temp_ << "x" << spec.n_cols_temp_ << "x" << spec.n_sheets_temp_ << "\n"
            << "Input size                  : " << input_size_gb << " GB (" << input_size_bytes << " bytes)\n"
            << "Output size                 : " << output_size_gb << " GB (" << output_size_bytes << " bytes)\n"
            << "Temp size                   : " << temp_size_gb << " GB (" << temp_size_bytes << " bytes)\n"
            << "Required memory             : " << mem_gb << " GB (" << mem_size_bytes << " bytes)\n"
            << std::endl;
        if (mem_gb > gpu_mem) {
            std::cerr << "[ERROR] GPU memory size is less than the required size" << std::endl;
            return 1;
        }

        std::cout << "SETUP:" << std::endl;
        const auto setup_tp0 = std::chrono::high_resolution_clock::now();

        std::cout << "  - Allocating memory: ";
        Tensor3D<Number> tensor3d_A(spec.n_cols_A_, spec.n_rows_A_, spec.n_sheets_A_, 0);
        Tensor3D<Number> tensor3d_B(spec.n_cols_B_, spec.n_rows_B_, spec.n_sheets_B_, 0);
        Tensor3D<Number> tensor3d_C(spec.n_cols_C_, spec.n_rows_C_, spec.n_sheets_C_, 0);
        Tensor3D<Number> tensor3d_temp(spec.n_cols_temp_, spec.n_rows_temp_, spec.n_sheets_temp_, 0);
        const auto setup_tp1 = std::chrono::high_resolution_clock::now();
        std::chrono::duration<double, std::milli> setup_dt1 = setup_tp1 - setup_tp0;
        std::cout << setup_dt1.count() << " ms (" << setup_dt1.count() << " ms total)" << std::endl;

        std::cout << "  - Initializing tensors: ";
        if (is_random) {
            std::cout << "  (random) ";
            tensor3d_A.randomize(seed);
            tensor3d_B.randomize(seed+1);
        } else if (is_increasing) {
            std::cout << "  (increasing) ";
            for (size_t i = 0; i < size_A; ++i) tensor3d_A.vector_[i] = Number(i);
            for (size_t i = 0; i < size_B; ++i) tensor3d_B.vector_[i] = Number(i);
        } else if (is_increasing) {
            std::cout << "  (decreasing) ";
            for (size_t i = 0; i < size_A; ++i) tensor3d_A.vector_[i] = Number(size_A - i);
            for (size_t i = 0; i < size_B; ++i) tensor3d_B.vector_[i] = Number(size_B - i);
        } else {
            std::cerr << "[ERROR] Invalid initialization method" << std::endl;
            exit(1);
        }
        const auto setup_tp2 = std::chrono::high_resolution_clock::now();
        std::chrono::duration<double, std::milli> setup_step_dt2 = setup_tp2 - setup_tp1;
        std::chrono::duration<double, std::milli> setup_total_dt2 = setup_tp2 - setup_tp0;
        std::cout << setup_step_dt2.count() << " ms (" << setup_total_dt2.count() << " ms total)" << std::endl;

        std::cout << "  - Creating GPU streams: ";
        hipStream_t stream;
        hip_check_error(hipStreamCreate(&stream), "hipStreamCreate");
        const auto setup_tp3 = std::chrono::high_resolution_clock::now();
        std::chrono::duration<double, std::milli> setup_step_dt3 = setup_tp3 - setup_tp2;
        std::chrono::duration<double, std::milli> setup_total_dt3 = setup_tp3 - setup_tp0;
        std::cout << setup_step_dt3.count() << " ms (" << setup_total_dt3.count() << " ms total)" << std::endl;

        std::cout << "  - Creating GPU events: ";
        hipEvent_t e0, e1, e2, e3, e4, e5;
        hip_check_error(hipEventCreate(&e0), "hipEventCreate");
        hip_check_error(hipEventCreate(&e1), "hipEventCreate");
        hip_check_error(hipEventCreate(&e2), "hipEventCreate");
        hip_check_error(hipEventCreate(&e3), "hipEventCreate");
        hip_check_error(hipEventCreate(&e4), "hipEventCreate");
        hip_check_error(hipEventCreate(&e5), "hipEventCreate");
        const auto setup_tp4 = std::chrono::high_resolution_clock::now();
        std::chrono::duration<double, std::milli> setup_step_dt4 = setup_tp4 - setup_tp3;
        std::chrono::duration<double, std::milli> setup_total_dt4 = setup_tp4 - setup_tp0;
        std::cout << setup_step_dt4.count() << " ms (" << setup_total_dt4.count() << " ms total)" << std::endl;

        std::cout << "Tensor3D_Kernel_2In_1Out:" << std::endl;
        const auto gpu_tp0 = std::chrono::high_resolution_clock::now();
        hip_check_error(hipEventRecord(e0, stream), "hipEventRecord");

        const auto gpu_step_1 = "Allocate device memory";
        Number* gpu_data_A = nullptr;
        Number* gpu_data_B = nullptr;
        Number* gpu_data_C = nullptr;
        Number* gpu_data_temp = nullptr;

        hip_check_error(hipMallocAsync(&gpu_data_A, size_A_bytes, stream), "hipMallocAsync");
        hip_check_error(hipMallocAsync(&gpu_data_B, size_B_bytes, stream), "hipMallocAsync");
        hip_check_error(hipMallocAsync(&gpu_data_C, size_C_bytes, stream), "hipMallocAsync");
        if (size_temp_bytes > 0) {
            hip_check_error(hipMallocAsync(&gpu_data_temp, size_temp_bytes, stream), "hipMallocAsync");
        }
        hip_check_error(hipEventRecord(e1, stream), "hipEventRecord");
        std::chrono::high_resolution_clock::time_point gpu_tp1{};
        hip_check_error(hipStreamAddCallback(stream, report_completion_time_callback, &gpu_tp1, NULL_FLAGS), "hipStreamAddCallback");

        const auto gpu_step_2 = "Copy data to device";
        hip_check_error(hipMemcpyAsync(gpu_data_A, tensor3d_A.data(), size_A_bytes, hipMemcpyHostToDevice, stream), "hipMemcpyAsync");
        hip_check_error(hipMemcpyAsync(gpu_data_B, tensor3d_B.data(), size_B_bytes, hipMemcpyHostToDevice, stream), "hipMemcpyAsync");
        hip_check_error(hipEventRecord(e2, stream), "hipEventRecord");
        std::chrono::high_resolution_clock::time_point gpu_tp2{};
        hip_check_error(hipStreamAddCallback(stream, report_completion_time_callback, &gpu_tp2, NULL_FLAGS), "hipStreamAddCallback");

        const auto gpu_step_3 = "Compute kernel";
        kernel.run_device_kernel(gpu_data_A, gpu_data_B, gpu_data_C, gpu_data_temp, stream);
        hip_check_error(hipEventRecord(e3, stream), "hipEventRecord");
        std::chrono::high_resolution_clock::time_point gpu_tp3{};
        hip_check_error(hipStreamAddCallback(stream, report_completion_time_callback, &gpu_tp3, NULL_FLAGS), "hipStreamAddCallback");

        const auto gpu_step_4 = "Copy result back to host";
        hip_check_error(hipMemcpyAsync(tensor3d_C.data(), gpu_data_C, size_C_bytes, hipMemcpyDeviceToHost, stream), "hipMemcpyAsync");
        if (size_temp_bytes > 0) {
            hip_check_error(hipMemcpyAsync(tensor3d_temp.data(), gpu_data_temp, size_temp_bytes, hipMemcpyDeviceToHost, stream), "hipMemcpyAsync");
        }
        hip_check_error(hipEventRecord(e4, stream), "hipEventRecord");
        std::chrono::high_resolution_clock::time_point gpu_tp4{};
        hip_check_error(hipStreamAddCallback(stream, report_completion_time_callback, &gpu_tp4, NULL_FLAGS), "hipStreamAddCallback");

        const auto gpu_step_5 = "Free device memory";
        hip_check_error(hipFreeAsync(gpu_data_A, stream), "hipFreeAsync");
        hip_check_error(hipFreeAsync(gpu_data_B, stream), "hipFreeAsync");
        hip_check_error(hipFreeAsync(gpu_data_C, stream), "hipFreeAsync");
        if (size_temp_bytes > 0) {
            hip_check_error(hipFreeAsync(gpu_data_temp, stream), "hipFreeAsync");
        }
        hip_check_error(hipEventRecord(e5, stream), "hipEventRecord");
        std::chrono::high_resolution_clock::time_point gpu_tp5{};
        hip_check_error(hipStreamAddCallback(stream, report_completion_time_callback, &gpu_tp5, NULL_FLAGS), "hipStreamAddCallback");

        // Wait for stream to finish
        hip_check_error(hipStreamSynchronize(stream), "hipStreamSynchronize");

        // Print execution time
        constexpr int row_header_width = 22;
        constexpr int field_name_width = 25;
        float gpu_step_dt1 = 0.0f, gpu_step_dt2 = 0.0f, gpu_step_dt3 = 0.0f, gpu_step_dt4 = 0.0f, gpu_step_dt5 = 0.0f;
        float gpu_total_dt1 = 0.0f, gpu_total_dt2 = 0.0f, gpu_total_dt3 = 0.0f, gpu_total_dt4 = 0.0f, gpu_total_dt5 = 0.0f;

        std::chrono::duration<double, std::milli> chrono_step_dt1 = gpu_tp1 - gpu_tp0;
        std::chrono::duration<double, std::milli> chrono_total_dt1 = gpu_tp1 - gpu_tp0;
        hip_check_error(hipEventElapsedTime(&gpu_step_dt1, e0, e1), "hipEventElapsedTime");
        hip_check_error(hipEventElapsedTime(&gpu_total_dt1, e0, e1), "hipEventElapsedTime");
        std::cout << "1 - " << std::setw(row_header_width) << "hipEventElapsedTime " << std::setw(field_name_width) << gpu_step_1 << ": " << chrono_step_dt1.count() << " ms (" << chrono_total_dt1.count() << " ms total)" << std::endl;
        std::cout << "1 - " << std::setw(row_header_width) << "std::chrono::duration " << std::setw(field_name_width) << gpu_step_1 << ": " << gpu_step_dt1 << " ms (" << gpu_total_dt1 << " ms total)" << std::endl;

        std::chrono::duration<double, std::milli> chrono_step_dt2 = gpu_tp2 - gpu_tp1;
        std::chrono::duration<double, std::milli> chrono_total_dt2 = gpu_tp2 - gpu_tp0;
        hip_check_error(hipEventElapsedTime(&gpu_step_dt2, e1, e2), "hipEventElapsedTime");
        hip_check_error(hipEventElapsedTime(&gpu_total_dt2, e0, e2), "hipEventElapsedTime");
        std::cout << "2 - " << std::setw(row_header_width) << "hipEventElapsedTime " << std::setw(field_name_width) << gpu_step_2 << ": " << chrono_step_dt2.count() << " ms (" << chrono_total_dt2.count() << " ms total)" << std::endl;
        std::cout << "2 - " << std::setw(row_header_width) << "std::chrono::duration " << std::setw(field_name_width) << gpu_step_2 << ": " << gpu_step_dt2 << " ms (" << gpu_total_dt2 << " ms total)" << std::endl;

        std::chrono::duration<double, std::milli> chrono_step_dt3 = gpu_tp3 - gpu_tp2;
        std::chrono::duration<double, std::milli> chrono_total_dt3 = gpu_tp3 - gpu_tp0;
        hip_check_error(hipEventElapsedTime(&gpu_step_dt3, e2, e3), "hipEventElapsedTime");
        hip_check_error(hipEventElapsedTime(&gpu_total_dt3, e0, e3), "hipEventElapsedTime");
        std::cout << "3 - " << std::setw(row_header_width) << "hipEventElapsedTime " << std::setw(field_name_width) << gpu_step_3 << ": " << chrono_step_dt3.count() << " ms (" << chrono_total_dt3.count() << " ms total)" << std::endl;
        std::cout << "3 - " << std::setw(row_header_width) << "std::chrono::duration " << std::setw(field_name_width) << gpu_step_3 << ": " << gpu_step_dt3 << " ms (" << gpu_total_dt3 << " ms total)" << std::endl;

        std::chrono::duration<double, std::milli> chrono_step_dt4 = gpu_tp4 - gpu_tp3;
        std::chrono::duration<double, std::milli> chrono_total_dt4 = gpu_tp4 - gpu_tp0;
        hip_check_error(hipEventElapsedTime(&gpu_step_dt4, e3, e4), "hipEventElapsedTime");
        hip_check_error(hipEventElapsedTime(&gpu_total_dt4, e0, e4), "hipEventElapsedTime");
        std::cout << "4 - " << std::setw(row_header_width) << "hipEventElapsedTime " << std::setw(field_name_width) << gpu_step_4 << ": " << chrono_step_dt4.count() << " ms (" << chrono_total_dt4.count() << " ms total)" << std::endl;
        std::cout << "4 - " << std::setw(row_header_width) << "std::chrono::duration " << std::setw(field_name_width) << gpu_step_4 << ": " << gpu_step_dt4 << " ms (" << gpu_total_dt4 << " ms total)" << std::endl;

        std::chrono::duration<double, std::milli> chrono_step_dt5 = gpu_tp5 - gpu_tp4;
        std::chrono::duration<double, std::milli> chrono_total_dt5 = gpu_tp5 - gpu_tp0;
        hip_check_error(hipEventElapsedTime(&gpu_step_dt5, e4, e5), "hipEventElapsedTime");
        hip_check_error(hipEventElapsedTime(&gpu_total_dt5, e0, e5), "hipEventElapsedTime");
        std::cout << "5 - " << std::setw(row_header_width) << "hipEventElapsedTime " << std::setw(field_name_width) << gpu_step_5 << ": " << chrono_step_dt5.count() << " ms (" << chrono_total_dt5.count() << " ms total)" << std::endl;
        std::cout << "5 - " << std::setw(row_header_width) << "std::chrono::duration " << std::setw(field_name_width) << gpu_step_5 << ": " << gpu_step_dt5 << " ms (" << gpu_total_dt5 << " ms total)" << std::endl;

        // Clean up
        hip_check_error(hipEventDestroy(e0), "hipEventDestroy");
        hip_check_error(hipEventDestroy(e1), "hipEventDestroy");
        hip_check_error(hipEventDestroy(e2), "hipEventDestroy");
        hip_check_error(hipEventDestroy(e3), "hipEventDestroy");
        hip_check_error(hipEventDestroy(e4), "hipEventDestroy");
        hip_check_error(hipEventDestroy(e5), "hipEventDestroy");
        hip_check_error(hipStreamDestroy(stream), "hipStreamDestroy");

        const auto cpu_tp0 = std::chrono::high_resolution_clock::now();

        constexpr int check_field_width = 26;
        std::cout << "CHECK WITH CPU:" << std::endl;
        const auto cpu_step_1 = "Convert data to Eigen (skipped for Tensor3D)";
        const auto cpu_tp1 = std::chrono::high_resolution_clock::now();
        std::chrono::duration<double, std::milli> cpu_step_dt1 = cpu_tp1 - cpu_tp0;
        std::chrono::duration<double, std::milli> cpu_total_dt1 = cpu_tp1 - cpu_tp0;
        std::cout << " - " << std::setw(check_field_width) << cpu_step_1 << ": " << cpu_step_dt1.count() << " ms (" << cpu_total_dt1.count() << " ms total)" << std::endl;

        const auto cpu_step_2 = "Compute result with CPU";
        const auto tensor3d_C_cpu = kernel.run_host_kernel(tensor3d_A, tensor3d_B);
        const auto& tensor3d_result_gpu = tensor3d_C;
        const auto& tensor3d_result_cpu = tensor3d_C_cpu;
        const auto cpu_tp2 = std::chrono::high_resolution_clock::now();
        std::chrono::duration<double, std::milli> cpu_step_dt2 = cpu_tp2 - cpu_tp1;
        std::chrono::duration<double, std::milli> cpu_total_dt2 = cpu_tp2 - cpu_tp0;
        std::cout << " - " << std::setw(check_field_width) << cpu_step_2 << ": " << cpu_step_dt2.count() << " ms (" << cpu_total_dt2.count() << " ms total)" << std::endl;

        const auto cpu_step_3 = "Compute error tensor3d and find max error";
        double E_max = 0;
        long E_max_row = 0, E_max_col = 0, E_max_sheet = 0;
        double E_max_pct = 0;
        long E_pct_max_row = 0, E_pct_max_col = 0, E_pct_max_sheet = 0;

        // row-major representation: innermost loop should iterate over elements of the same sheet/row
        const long e_rows = tensor3d_result_cpu.rows(), e_cols = tensor3d_result_cpu.cols(), e_sheets = tensor3d_result_cpu.sheets();
        Tensor3D<double> tensor3d_E(e_cols, e_rows, e_sheets, 0);
        Tensor3D<double> tensor3d_E_pct(e_cols, e_rows, e_sheets, 0);
        for (long sheet = 0; sheet < e_sheets; ++sheet) {
            for (long row = 0; row < e_rows; ++row) {
                for (long col = 0; col < e_cols; ++col) {
                    const double result_gpu_row_col = double(tensor3d_result_gpu(col, row, sheet));
                    const double result_cpu_row_col = double(tensor3d_result_cpu(col, row, sheet));
                    const double delta = result_gpu_row_col - result_cpu_row_col;
                    const bool results_are_identical = (
                        (std::isnan(result_gpu_row_col) && std::isnan(result_cpu_row_col))
                        || (std::isinf(result_gpu_row_col) && std::isinf(result_cpu_row_col) && std::isnan(delta))
                    );
                    const double e = results_are_identical ? 0 : delta;
                    const double e_abs = std::abs(e);
                    const double e_ref = double(tensor3d_result_cpu(col, row, sheet));
                    const double e_ref_abs = std::abs(e_ref);
                    const double e_pct = e_ref_abs > 0 ? 100.0 * e_abs / e_ref_abs : 0.0;
                    tensor3d_E(col, row, sheet) = e;
                    tensor3d_E_pct(col, row, sheet) = e_pct;
                    if (e_abs > E_max) {
                        E_max = e_abs;
                        E_max_row = row;
                        E_max_col = col;
                        E_max_sheet = sheet;
                    }
                    if (e_pct > E_max_pct) {
                        E_max_pct = e_pct;
                        E_pct_max_row = row;
                        E_pct_max_col = col;
                        E_pct_max_sheet = sheet;
                    }
                }
            }
        }
        const auto cpu_tp3 = std::chrono::high_resolution_clock::now();
        std::chrono::duration<double, std::milli> cpu_step_dt3 = cpu_tp3 - cpu_tp2;
        std::chrono::duration<double, std::milli> cpu_total_dt3 = cpu_tp3 - cpu_tp0;
        std::cout << " - " << std::setw(check_field_width) << cpu_step_3 << ": " << cpu_step_dt3.count() << " ms (" << cpu_total_dt3.count() << " ms total)" << std::endl;

        if (errors) {
            std::cout << "Non-zero error elements:\n";
            bool found_errors = false;
            for (int i = 0; i < tensor3d_E.rows(); ++i) {
                for (int j = 0; j < tensor3d_E.cols(); ++j) {
                    for (int k = 0; k < tensor3d_E.sheets(); ++k) {
                        if (tensor3d_E(i, j, k) != 0.0) {
                            found_errors = true;
                            std::cout << "(" << i << ", " << j << ", " << k << "): "
                                    << "result gpu =" << static_cast<Printable_Number>(tensor3d_result_gpu(i, j, k)) << ", "
                                    << "result cpu =" << static_cast<Printable_Number>(tensor3d_result_cpu(i, j, k)) << ", "
                                    << "E          =" << static_cast<Printable_Number>(tensor3d_E(i, j, k)) << "\n";
                        }
                    }
                }
            }
            if (!found_errors) {
                std::cout << "No non-zero error elements found\n";
            }
        }

        if (verbose) {
            const Eigen::IOFormat eigen_format(4, 0, ", ", "\n", "  [", "]");
            std::cout << "A    :\n";
            tensor3d_A.print(std::cout);
            std::cout << "B    :\n";
            tensor3d_B.print(std::cout);
            std::cout << "C_gpu:\n";
            tensor3d_result_gpu.print(std::cout);
            std::cout << "C_cpu:\n";
            tensor3d_result_cpu.print(std::cout);
            if ((spec.n_rows_temp_ > 0) && (spec.n_cols_temp_ > 0) && (spec.n_sheets_temp_)) {
                std::cout << "tmp  :\n";
                tensor3d_temp.print(std::cout);
            }
            if (errors) {
                std::cout << "E    :\n";
                tensor3d_E.print(std::cout);
                std::cout << "E_pct:\n";
                tensor3d_E_pct.print(std::cout);
            }
        }

        const auto tp_done = std::chrono::high_resolution_clock::now();
        std::chrono::duration<double, std::milli> total_dt = tp_done - setup_tp0;
        std::cout << "DONE: " << total_dt.count() << " ms total" << std::endl;
        std::cout << "Max error     : " << E_max << " at (" << E_max_row << ", " << E_max_col << ", " << E_max_sheet << ")" << std::endl;
        std::cout << "Max error pct : " << E_max_pct << " at (" << E_pct_max_row << ", " << E_pct_max_col << ", " << E_pct_max_sheet << ")" << std::endl;
        std::cout << "Gross speedup : " << (cpu_step_dt2.count()/gpu_step_dt3) << std::endl;
        std::cout << "Net speedup   : " << (cpu_total_dt2.count()/gpu_total_dt5) << std::endl;

        return 0;
    }
};
